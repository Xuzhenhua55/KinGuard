import argparse
import torch
import math
from tqdm import tqdm
from ModelUtils import ModelUtils
from DatasetUtils import DatasetUtils

def filter_valid_ppl(ppl_list, max_threshold=1e6):
    """
    è¿‡æ»¤æ‰ NaNã€inf å’Œè¶…è¿‡ max_threshold çš„å¼‚å¸¸å€¼ã€‚
    è¿”å›æœ‰æ•ˆå€¼åˆ—è¡¨å’Œå¼‚å¸¸å€¼æ•°é‡ã€‚
    """
    valid_list = []
    invalid_count = 0
    for p in ppl_list:
        if math.isnan(p) or math.isinf(p) or p > max_threshold:
            invalid_count += 1
        else:
            valid_list.append(p)
    return valid_list, invalid_count


def compute_ppl(model, tokenizer, text, device="cuda"):
    """
    è®¡ç®—å•ä¸ªæ ·æœ¬çš„ PPLã€‚
    """
    inputs = tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        max_length=1024,
    )
    input_ids = inputs["input_ids"].to(device)
    attention_mask = inputs["attention_mask"].to(device)

    with torch.no_grad():
        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)
        loss = outputs.loss
        ppl = torch.exp(loss).item()
        return ppl

def main(args):
    # 1. åŠ è½½æ¨¡å‹
    model, tokenizer = ModelUtils.load_model(
        model_path=args.model_path,
        lora_adapters=args.lora_adapters,
        device=args.device,
        quantize_bits=args.quantize_bits,
    )

    # 2. åŠ è½½æ•°æ®é›†
    dataset = DatasetUtils.load_dataset(
        path=args.dataset_path,
        source_format=args.source_format,
        target_format=args.target_format,
        max_samples=args.max_samples
    )

    ppl_input_list = []
    ppl_input_output_list = []

    input_exceed_cnt = 0
    input_output_exceed_cnt = 0

    for sample in tqdm(dataset, desc="ğŸŒŸ æ­£åœ¨è¯„ä¼° PPL"):
        instruction = sample.get("instruction", "").strip()
        input_text = sample.get("input", "").strip()
        output = sample.get("output", "").strip()

        if input_text:
            prompt_input = f"{instruction}\n{input_text}"
        else:
            prompt_input = instruction
        prompt_input_output = f"{prompt_input}\n{output}"

        ppl_input = compute_ppl(model, tokenizer, prompt_input, device=args.device)
        ppl_input_output = compute_ppl(model, tokenizer, prompt_input_output, device=args.device)

        ppl_input_list.append(ppl_input)
        ppl_input_output_list.append(ppl_input_output)

        if args.ppl_threshold_input is not None and ppl_input > args.ppl_threshold_input:
            input_exceed_cnt += 1
        if args.ppl_threshold_input_output is not None and ppl_input_output > args.ppl_threshold_input_output:
            input_output_exceed_cnt += 1

    # è¿‡æ»¤å¼‚å¸¸å€¼ï¼Œä»…ä¿ç•™æœ‰æ•ˆå€¼å‚ä¸ç»Ÿè®¡
    valid_ppl_input_list, input_invalid_cnt = filter_valid_ppl(ppl_input_list)
    valid_ppl_input_output_list, input_output_invalid_cnt = filter_valid_ppl(ppl_input_output_list)

    # å¹³å‡å€¼è®¡ç®—ï¼ˆé˜²æ­¢é™¤ä»¥ 0ï¼‰
    avg_ppl_input = (
        sum(valid_ppl_input_list) / len(valid_ppl_input_list)
        if valid_ppl_input_list else float('nan')
    )
    avg_ppl_input_output = (
        sum(valid_ppl_input_output_list) / len(valid_ppl_input_output_list)
        if valid_ppl_input_output_list else float('nan')
    )

    # æ‰“å°ç»“æœ
    print("\nğŸ“Š PPL è¯„ä¼°ç»“æœï¼ˆä»…ç»Ÿè®¡æœ‰æ•ˆå€¼ï¼‰ï¼š")
    print(f" - Average PPL (prompt only)......: {avg_ppl_input:.4f} (æœ‰æ•ˆæ ·æœ¬æ•°: {len(valid_ppl_input_list)})")
    print(f" - Average PPL (prompt + output)..: {avg_ppl_input_output:.4f} (æœ‰æ•ˆæ ·æœ¬æ•°: {len(valid_ppl_input_output_list)})")
    print(f" - å¿½ç•¥æ— æ•ˆ PPL æ•°é‡ï¼ˆprompt onlyï¼‰......: {input_invalid_cnt}")
    print(f" - å¿½ç•¥æ— æ•ˆ PPL æ•°é‡ï¼ˆprompt + outputï¼‰..: {input_output_invalid_cnt}")

    # é˜ˆå€¼ç»Ÿè®¡ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ï¼‰
    if args.ppl_threshold_input is not None:
        ratio = input_exceed_cnt / len(ppl_input_list) * 100
        print(f" - PPL > {args.ppl_threshold_input} [prompt only].......: {input_exceed_cnt}/{len(ppl_input_list)} ({ratio:.2f}%)")
    if args.ppl_threshold_input_output is not None:
        ratio = input_output_exceed_cnt / len(ppl_input_output_list) * 100
        print(f" - PPL > {args.ppl_threshold_input_output} [prompt+output]..: {input_output_exceed_cnt}/{len(ppl_input_output_list)} ({ratio:.2f}%)")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="è®¡ç®— PPL æŒ‡æ ‡")
    parser.add_argument("--model_path", type=str, required=True, help="æ¨¡å‹è·¯å¾„ (HuggingFace æ ¼å¼æˆ– bin)")
    parser.add_argument('--lora_adapters', type=str, nargs='+', default=[], help="LoRA é€‚é…å™¨è·¯å¾„åˆ—è¡¨")
    parser.add_argument("--device", type=str, default="cuda:0", help="è®¡ç®—è®¾å¤‡")
    parser.add_argument("--quantize_bits", type=int, choices=[4, 8, 16, 32], default=None, help="é‡åŒ–ä½æ•°")
    parser.add_argument("--dataset_path", type=str, required=True, help="alpaca æ ¼å¼æ•°æ®é›†è·¯å¾„")
    parser.add_argument("--max_samples", type=int, default=None, help="æœ€å¤šè¯„ä¼°çš„æ ·æœ¬æ•°é‡")
    parser.add_argument("--source_format", type=str, default="alpaca", help="åŸå§‹æ•°æ®é›†æ ¼å¼ï¼ˆå¦‚ 'firefly', 'alpaca'ï¼‰")
    parser.add_argument("--target_format", type=str, default="alpaca", help="ç›®æ ‡æ•°æ®é›†æ ¼å¼ï¼ˆå¦‚ 'alpaca'ï¼‰")
    parser.add_argument("--ppl_threshold_input", type=float, default=None, help="PPL é˜ˆå€¼ï¼ˆprompt onlyï¼‰")
    parser.add_argument("--ppl_threshold_input_output", type=float, default=None, help="PPL é˜ˆå€¼ï¼ˆprompt + outputï¼‰")
    args = parser.parse_args()

    main(args)
